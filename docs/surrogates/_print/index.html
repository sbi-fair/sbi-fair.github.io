<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=/docs/surrogates/><link rel=alternate type=application/rss+xml href=/docs/surrogates/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Surrogates | SBI-FAIR</title><meta name=description content="A list of surrogates we look at"><meta property="og:title" content="Surrogates"><meta property="og:description" content="A list of surrogates we look at
"><meta property="og:type" content="website"><meta property="og:url" content="/docs/surrogates/"><meta itemprop=name content="Surrogates"><meta itemprop=description content="A list of surrogates we look at
"><meta name=twitter:card content="summary"><meta name=twitter:title content="Surrogates"><meta name=twitter:description content="A list of surrogates we look at
"><link rel=preload href=/scss/main.min.92d2bf82a410cd58c2b4fa1c71e96d2d6f4b42d746be6406a0dc6e77326dce57.css as=style integrity="sha256-ktK/gqQQzVjCtPocceltLW9LQtdGvmQGoNxudzJtzlc=" crossorigin=anonymous><link href=/scss/main.min.92d2bf82a410cd58c2b4fa1c71e96d2d6f4b42d746be6406a0dc6e77326dce57.css rel=stylesheet integrity="sha256-ktK/gqQQzVjCtPocceltLW9LQtdGvmQGoNxudzJtzlc=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg></span><span class=navbar-brand__name>SBI-FAIR</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/about/><span>About</span></a></li><li class=nav-item><a class="nav-link active" href=/docs/><span>Documentation</span></a></li><li class=nav-item><a class=nav-link href=/docs/publications/><span>Publications</span></a></li><li class=nav-item><a class="nav-link active" href=/docs/surrogates/><span>Surrogates</span></a></li><li class=nav-item><a class=nav-link href=/docs/software/><span>Software</span></a></li><li class=nav-item><a class=nav-link href=/docs/notes/><span>Notes</span></a></li><li class=nav-item><a class=nav-link href=/blog/><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/community/><span>Community</span></a></li></ul></div><div class="d-none d-lg-block"><div class=td-search><div class=td-search__icon></div><input type=search class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/surrogates/>Return to the regular view of this page</a>.</p></div><h1 class=title>Surrogates</h1><div class=lead>A list of surrogates we look at</div><ul><li>1: <a href=#pg-541c846fdc6fb55135b27065f2879d73>AutoPhaseNN: unsupervised physics-aware deep learning of 3D nanoscale Bragg coherent diffraction imaging</a></li><li>2: <a href=#pg-e87c590decacea82502a53d7c30c5035>Calorimeter surrogates</a></li><li>3: <a href=#pg-386ca1030e8123ddf937ecb1eac2905c>Virtual tissue</a></li><li>4: <a href=#pg-c81d71fde3c0ee4014394d74adc53de0>Cosmoflow</a></li><li>5: <a href=#pg-f33b00fce1cb69e54b44c3dacba3bfad>Fully ionized plasma fluid model closures</a></li><li>6: <a href=#pg-78e52a1336c6e0869c51f7cf3eef7d30>Ions in nanoconfinement</a></li><li>7: <a href=#pg-4ffb8f290e64e79568dc14ea45423d53>Molecule docking</a></li><li>8: <a href=#pg-da679368f9d15b0486abed0d11a2ce9a>miniWeatherML</a></li><li>9: <a href=#pg-6e66623ebf80ce302fd399a8dd6f8d7b>OSMI</a></li><li>10: <a href=#pg-e825d671002d82761de7d86a532a7008>Particle dynamics</a></li><li>11: <a href=#pg-d65c9f63f13fcf64fe06b834161e6a0d>PtychoNN: deep learning network for ptychographic imaging that predicts sample amplitude and phase from diffraction data.</a></li></ul><div class=content><p>A list of surrogates</p></div></div><div class=td-content><h1 id=pg-541c846fdc6fb55135b27065f2879d73>1 - AutoPhaseNN: unsupervised physics-aware deep learning of 3D nanoscale Bragg coherent diffraction imaging</h1><div class=lead>A DL-based approach which learns to solve the phase problem in 3D X-ray Bragg coherent diffraction imaging (BCDI) without labeled data.</div><hr><h2 id=metadata>Metadata<a class=td-heading-self-link href=#metadata aria-label="Heading self-link"></a></h2><hr><p><strong>Model</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/models/a/autophasenn.json>autophasenn.json</a></p><p><strong>Datasets</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/datasets/a/autoPhaseNN_aicdi.json>autoPhaseNN_aicdi.json</a></p><hr><blockquote><p>Adapted from Yao, Y. <em>et. al</em> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> under CC-BY <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p></blockquote><p>AutoPhaseNN <sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, a physics-aware unsupervised deep convolutional neural network
(CNN) that learns to solve the phase problem without ever being shown real space
images of the sample amplitude or phase. By incorporating the physics of the
X-ray scattering into the network design and training, AutoPhaseNN learns to
predict both the amplitude and phase of the sample given the measured
diffraction intensity alone. Additionally, unlike previous deep learning models,
AutoPhaseNN does not need the ground truth images of sample’s amplitude and
phase at any point, either in training or in deployment. Once trained, the
physical model is discarded and only the CNN portion is needed which has learned
the data inversion from reciprocal space to real space and is ~100 times faster
than the iterative phase retrieval with comparable image quality. Furthermore,
we show that by using AutoPhaseNN’s prediction as the learned prior to iterative
phase retrieval, we can achieve consistently higher image quality, than neural
network prediction alone, at 10 times faster speed than iterative phase
retrieval alone.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:910px><img class=card-img-top src=/docs/surrogates/autophasenn/autophasenn1_huf90a121ae4129385ddbbadbc4dfa22cd_382578_900x0_resize_catmullrom_3.png width=900 height=429><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Fig. 1: Schematic of the neural network structure of AutoPhaseNN model during training.
a) The model consists of a 3D CNN and the X-ray scattering forward model. The 3D
CNN is implemented with a convolutional auto-encoder and two deconvolutional
decoders using the convolutional, maximum pooling, upsampling and zero padding
layers. The physical knowledge is enforced via the Sigmoid and Tanh activation
functions in the final layers. b The X-ray scattering forward model includes the
numerical modeling of diffraction and the image shape constraints. It takes the
amplitude and phase from the 3D CNN output to form the complex image. Then the
estimated diffraction pattern is obtained from the FT of the current estimation
of the real space image.
<small class=text-body-secondary><br>Image from: Yao, Y. et al / CC-BY</small></p></figcaption></figure><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Yao, Y., Chan, H., Sankaranarayanan, S. et al. AutoPhaseNN: unsupervised physics-aware deep learning of 3D nanoscale Bragg coherent diffraction imaging. npj Comput Mater 8, 124 (2022). <a href=https://doi.org/10.1038/s41524-022-00803-w>https://doi.org/10.1038/s41524-022-00803-w</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=http://creativecommons.org/licenses/by/4.0/>http://creativecommons.org/licenses/by/4.0/</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-e87c590decacea82502a53d7c30c5035>2 - Calorimeter surrogates</h1><div class=lead>The Kaggle calorimeter challenge uses generative AI to produce a surrogate for the Monte Carlo calculation of a calorimeter response to an incident particle (ATLAS data at LHC calculated with GEANT4).</div><h2 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h2><p>The Kaggle calorimeter challenge uses generative AI to produce a
surrogate for the Monte Carlo calculation of a calorimeter response to
an incident particle (ATLAS data at LHC calculated with
GEANT4). Variational Auto Encoders, GANs, Normalizing Flows, and
Diffusion Models. We also have a surrogate using a Quantum Computer
(DWAVE) annealer to generate random samples. We have identified four
different surrogates that are available openly from Kaggle and later
submissions.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:938px><img class=card-img-top src=/docs/surrogates/calorimeter/caloremiter_hub1b4528fbc9f1add21b4ab579c06711a_1445091_928x710_fill_catmullrom_smart1_3.png width=928 height=710><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: CaloChallenge Dataset.</p></figcaption></figure><h2 id=details>Details<a class=td-heading-self-link href=#details aria-label="Heading self-link"></a></h2><p>Accurate simulation plays a crucial role in particle physics by
bridging theoretical models with experimental data to uncover the
universe&rsquo;s fundamental properties. At the Large Hadron Collider (LHC),
simulations based on Monte Carlo methods model the interactions of
billions of particles, including complex calorimeter shower
events—cascades of secondary particles produced when high-energy
particles hit detector materials. The widely-used Geant4
<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>
simulation toolkit provides highly detailed physics-based simulations,
but its computational cost is extremely high, making up over 75% of
the total simulation time
<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. With the upcoming High-Luminosity LHC
(HL-LHC)
<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup><sup>,</sup><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>
upgrade in 2029, the collider will generate larger
datasets with higher precision requirements, significantly increasing
the demand for computational resources. To mitigate this, researchers
are exploring generative models commonly used in image and text
generation—as surrogate models that can generate realistic calorimeter
showers at a fraction of the computational cost. In recent years,
several approaches based on Generative Adversarial Networks(GAN)
<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup><sup>-</sup>
<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup><sup>-</sup>
<sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup><sup>-</sup>
<sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup><sup>-</sup>
<sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup><sup>-</sup>
<sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup><sup>-</sup>
Diffusion
<sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup>
<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup><sup>,</sup>
<sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup><sup>,</sup>
<sup id=fnref:14><a href=#fn:14 class=footnote-ref role=doc-noteref>14</a></sup><sup>,</sup>
<sup id=fnref:15><a href=#fn:15 class=footnote-ref role=doc-noteref>15</a></sup><sup>,</sup>
<sup id=fnref:16><a href=#fn:16 class=footnote-ref role=doc-noteref>16</a></sup><sup>,</sup>
<sup id=fnref:17><a href=#fn:17 class=footnote-ref role=doc-noteref>17</a></sup><sup>,</sup>
<sup id=fnref:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup><sup>,</sup>
<sup id=fnref:19><a href=#fn:19 class=footnote-ref role=doc-noteref>19</a></sup>, Variational Autoencoders (VAEs)
<sup id=fnref:20><a href=#fn:20 class=footnote-ref role=doc-noteref>20</a></sup><sup>,</sup>
<sup id=fnref:21><a href=#fn:21 class=footnote-ref role=doc-noteref>21</a></sup><sup>,</sup>
<sup id=fnref:22><a href=#fn:22 class=footnote-ref role=doc-noteref>22</a></sup><sup>,</sup>
<sup id=fnref:23><a href=#fn:23 class=footnote-ref role=doc-noteref>23</a></sup><sup>,</sup>
<sup id=fnref:24><a href=#fn:24 class=footnote-ref role=doc-noteref>24</a></sup><sup>,</sup>
<sup id=fnref:25><a href=#fn:25 class=footnote-ref role=doc-noteref>25</a></sup><sup>,</sup>
<sup id=fnref:26><a href=#fn:26 class=footnote-ref role=doc-noteref>26</a></sup><sup>,</sup>
<sup id=fnref:27><a href=#fn:27 class=footnote-ref role=doc-noteref>27</a></sup><sup>,</sup>
<sup id=fnref:28><a href=#fn:28 class=footnote-ref role=doc-noteref>28</a></sup>
and Normalizing Flows
<sup id=fnref:29><a href=#fn:29 class=footnote-ref role=doc-noteref>29</a></sup><sup>-</sup><sup id=fnref:30><a href=#fn:30 class=footnote-ref role=doc-noteref>30</a></sup>
have been proposed. However, evaluating
these models remains challenging because the physical characteristics
of calorimeter showers differ significantly from traditional image-
and text-based data.
<sup id=fnref:31><a href=#fn:31 class=footnote-ref role=doc-noteref>31</a></sup><sup>-</sup>
<sup id=fnref:32><a href=#fn:32 class=footnote-ref role=doc-noteref>32</a></sup> conducted a rigorous evaluation of these
generative models using standard datasets and a diverse set of metrics
derived from physics, computer vision, and statistics. Although
<sup id=fnref1:31><a href=#fn:31 class=footnote-ref role=doc-noteref>31</a></sup>
sheds light on the existent correlations between layers, they do not
quantify correlations between layers and voxels. In this work, we
propose Correlation Frobenius Distance(CFD), an evaluation metric for
generative models of calorimeter shower simulation. This metric
measures how the consecutive layers and voxels of generated samples
are correlated with each other compared to Geant4 samples. CFD helps
evaluate the consistency of energy deposition patterns across layers,
capturing the spatial correlations in the calorimeter shower. Lower
CFD values indicate that the generated samples better preserve the
correlations observed in Geant4 simulations. We compared four
different models (CaloDream
<sup id=fnref1:19><a href=#fn:19 class=footnote-ref role=doc-noteref>19</a></sup>, CaloScore v2 <sup id=fnref1:18><a href=#fn:18 class=footnote-ref role=doc-noteref>18</a></sup>, CaloDiffusion
<sup id=fnref1:27><a href=#fn:27 class=footnote-ref role=doc-noteref>27</a></sup>, and CaloINN
<sup id=fnref:33><a href=#fn:33 class=footnote-ref role=doc-noteref>33</a></sup>) on Dataset 2
<sup id=fnref:34><a href=#fn:34 class=footnote-ref role=doc-noteref>34</a></sup> from CaloChallenge 2022
<sup id=fnref1:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup> for CFD, our observation reveals that CaloDream can capture
correlations between consecutive layers and voxels the
best. Furthermore, we explored the impact of using full versus mixed
precision modes during inference for CaloDiffusion. Our observation
shows that mixed precision inference does not speed up inference for
Dataset 1
<sup id=fnref:35><a href=#fn:35 class=footnote-ref role=doc-noteref>35</a></sup> and Dataset 2
<sup id=fnref1:35><a href=#fn:35 class=footnote-ref role=doc-noteref>35</a></sup>.​ However, it significantly improves inference time for Dataset 3
<sup id=fnref2:35><a href=#fn:35 class=footnote-ref role=doc-noteref>35</a></sup>, without compromising
performance.​ The Code is available in GitHub at
<sup id=fnref:36><a href=#fn:36 class=footnote-ref role=doc-noteref>36</a></sup>.</p><p>Additional relevant references include:</p><p><sup id=fnref:37><a href=#fn:37 class=footnote-ref role=doc-noteref>37</a></sup><sup>,</sup>
<sup id=fnref:38><a href=#fn:38 class=footnote-ref role=doc-noteref>38</a></sup><sup>,</sup></p><p>Team contributed refernces include</p><p><sup id=fnref:39><a href=#fn:39 class=footnote-ref role=doc-noteref>39</a></sup><sup>,</sup>
<sup id=fnref:40><a href=#fn:40 class=footnote-ref role=doc-noteref>40</a></sup><sup>,</sup>
<sup id=fnref:41><a href=#fn:41 class=footnote-ref role=doc-noteref>41</a></sup><sup>,</sup>
<sup id=fnref:42><a href=#fn:42 class=footnote-ref role=doc-noteref>42</a></sup><sup>,</sup></p><p><strong>References</strong></p><p>Team contributed refernces are marked in bold</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Agostinelli, Sea, et al. &ldquo;GEANT4—a simulation toolkit.&rdquo; <em>Nuclear instruments and methods in physics research section A: Accelerators, Spectrometers, Detectors and Associated Equipment</em> 506.3 (2003): 250-303.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Muškinja, Miha, John Derek Chapman, and Heather Gray. &ldquo;Geant4 performance optimization in the ATLAS experiment.&rdquo; <em>EPJ Web of Conferences</em>. Vol. 245. EDP Sciences, 2020.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>&ldquo;New Schedule for CERN&rsquo;s Accelerators.&rdquo; <em>CERN</em>, 5 Dec. 2023, [https://home.cern/news/news/accelerators/new-schedule-cerns-accelerators]:(<a href=https://home.cern/news/news/accelerators/new-schedule-cerns-accelerators)>https://home.cern/news/news/accelerators/new-schedule-cerns-accelerators)</a>. Accessed 28 Feb. 2025.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>&ldquo;Computing at CERN.&rdquo; <em>CERN</em>, <a href=https://home.web.cern.ch/science/computing>https://home.web.cern.ch/science/computing</a>. Accessed 28 Feb. 2025.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>ATLAS collaboration. &ldquo;Fast simulation of the ATLAS calorimeter system with Generative Adversarial Networks.&rdquo; <em>ATLAS PUB Note, CERN, Geneva</em> (2020).&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p>Ghosh, Aishik, and ATLAS collaboration. &ldquo;Deep generative models for fast shower simulation in ATLAS.&rdquo; <em>Journal of Physics: Conference Series</em>. Vol. 1525. No. 1. IOP Publishing, 2020.&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p>Giannelli, Michele Faucci, and Rui Zhang. &ldquo;CaloShowerGAN, a generative adversarial network model for fast calorimeter shower simulation.&rdquo; <em>The European Physical Journal Plus</em> 139.7 (2024): 597.&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p>Paganini, Michela, Luke de Oliveira, and Benjamin Nachman. &ldquo;Accelerating science with generative adversarial networks: an application to 3D particle showers in multilayer calorimeters.&rdquo; <em>Physical review letters</em> 120.4 (2018): 042003.&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9><p>de Oliveira, Luke, Michela Paganini, and Benjamin Nachman. &ldquo;Learning particle physics by example: location-aware generative adversarial networks for physics synthesis.&rdquo; <em>Computing and Software for Big Science</em> 1.1 (2017): 4.&#160;<a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10><p>Paganini, Michela, Luke de Oliveira, and Benjamin Nachman. &ldquo;CaloGAN: Simulating 3D high energy particle showers in multilayer electromagnetic calorimeters with generative adversarial networks.&rdquo; <em>Physical Review D</em> 97.1 (2018): 014021.&#160;<a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11><p>Acosta, Fernando Torales, et al. &ldquo;Comparison of point cloud and image-based models for calorimeter fast simulation.&rdquo; <em>Journal of Instrumentation</em> 19.05 (2024): P05003.&#160;<a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12><p>Amram, Oz, and Kevin Pedro. &ldquo;Denoising diffusion models with geometry adaptation for high fidelity calorimeter simulation.&rdquo; <em>Physical Review D</em> 108.7 (2023): 072014.&#160;<a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:13><p>Buhmann, Erik, et al. &ldquo;CaloClouds: fast geometry-independent highly-granular calorimeter simulation.&rdquo; <em>Journal of Instrumentation</em> 18.11 (2023): P11025.&#160;<a href=#fnref:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:14><p>Buhmann, Erik, et al. &ldquo;CaloClouds II: ultra-fast geometry-independent highly-granular calorimeter simulation.&rdquo; <em>Journal of Instrumentation</em> 19.04 (2024): P04020.&#160;<a href=#fnref:14 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:15><p>Cresswell, Jesse C., and Taewoo Kim. &ldquo;Scaling Up Diffusion and Flow-based XGBoost Models.&rdquo; <em>arXiv preprint arXiv:2408.16046</em> (2024).&#160;<a href=#fnref:15 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:16><p>Madula, T., and V. M. Mikuni. &ldquo;CaloLatent: Score-based Generative Modelling in the Latent Space for Calorimeter Shower Generation NeurIPS Workshop on Machine Learning and the Physical Sciences URL https://ml4physicalsciences. github. io/2023/files.&rdquo; <em>NeurIPS_ ML4PS_2023_19. pdf</em> (2023).&#160;<a href=#fnref:16 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:17><p>Mikuni, Vinicius, and Benjamin Nachman. &ldquo;Score-based generative models for calorimeter shower simulation.&rdquo; <em>Physical Review D</em> 106.9 (2022): 092009.&#160;<a href=#fnref:17 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:18><p>Mikuni, Vinicius, and Benjamin Nachman. &ldquo;CaloScore v2: single-shot calorimeter shower simulation with diffusion models.&rdquo; <em>Journal of Instrumentation</em> 19.02 (2024): P02001.&#160;<a href=#fnref:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:18 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:19><p>Favaro, Luigi, et al. &ldquo;CaloDREAM&ndash;Detector Response Emulation via Attentive flow Matching.&rdquo; <em>arXiv preprint arXiv:2405.09629</em> (2024).&#160;<a href=#fnref:19 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:19 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:20><p>Cresswell, Jesse C., et al. &ldquo;CaloMan: Fast generation of calorimeter showers with density estimation on learned manifolds.&rdquo; <em>arXiv preprint arXiv:2211.15380</em> (2022).&#160;<a href=#fnref:20 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:21><p>Buhmann, Erik, et al. &ldquo;Decoding photons: Physics in the latent space of a BIB-AE generative network.&rdquo; <em>EPJ Web of Conferences</em>. Vol. 251. EDP Sciences, 2021.&#160;<a href=#fnref:21 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:22><p>Buhmann, Erik, et al. &ldquo;Getting high: High fidelity simulation of high granularity calorimeters with high speed.&rdquo; <em>Computing and Software for Big Science</em> 5.1 (2021): 13.&#160;<a href=#fnref:22 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:23><p>Diefenbacher, Sascha, et al. &ldquo;New angles on fast calorimeter shower simulation.&rdquo; <em>Machine Learning: Science and Technology</em> 4.3 (2023): 035044.&#160;<a href=#fnref:23 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:24><p>Salamani, Dalila, Anna Zaborowska, and Witold Pokorski. &ldquo;MetaHEP: Meta learning for fast shower simulation of high energy physics experiments.&rdquo; <em>Physics Letters B</em> 844 (2023): 138079.&#160;<a href=#fnref:24 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:25><p>Abhishek, Abhishek, et al. &ldquo;CaloDVAE: Discrete variational autoencoders for fast calorimeter shower simulation.&rdquo; <em>arXiv preprint arXiv:2210.07430</em> (2022).&#160;<a href=#fnref:25 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:26><p>Caloqvae: Simulating high-energy particle calorimeter interactions using hybrid quantum-classical generative models&#160;<a href=#fnref:26 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:27><p>Hoque, Sehmimul, et al. &ldquo;CaloQVAE: Simulating high-energy particle-calorimeter interactions using hybrid quantum-classical generative models.&rdquo; <em>The European Physical Journal C</em> 84.12 (2024): 1-7.&#160;<a href=#fnref:27 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:27 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:28><p>Lu, Ian, et al. &ldquo;Zephyr quantum-assisted hierarchical Calo4pQVAE for particle-calorimeter interactions.&rdquo; <em>arXiv preprint arXiv:2412.04677</em> (2024).&#160;<a href=#fnref:28 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:29><p>Krause, Claudius, and David Shih. &ldquo;Fast and accurate simulations of calorimeter showers with normalizing flows.&rdquo; <em>Physical Review D</em> 107.11 (2023): 113003.&#160;<a href=#fnref:29 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:30><p>Schnake, Simon, Dirk Krücker, and Kerstin Borras. &ldquo;CaloPointFlow II generating calorimeter showers as point clouds.&rdquo; <em>arXiv preprint arXiv:2403.15782</em> (2024).&#160;<a href=#fnref:30 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:31><p>**Ahmad, Farzana Yasmin, Vanamala Venkataswamy, and Geoffrey Fox. &ldquo;A comprehensive evaluation of generative models in calorimeter shower simulation.&rdquo; <em>arXiv preprint arXiv:2406.12898</em> (2024). **&#160;<a href=#fnref:31 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:31 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:32><p>Krause, Claudius, et al. &ldquo;Calochallenge 2022: A community challenge for fast calorimeter simulation.&rdquo; <em>arXiv preprint arXiv:2410.21611</em> (2024).&#160;<a href=#fnref:32 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:33><p>Ernst, Florian, et al. &ldquo;Normalizing flows for high-dimensional detector simulations.&rdquo; <em>arXiv preprint arXiv:2312.09290</em> (2023).&#160;<a href=#fnref:33 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:34><p>Ahmad, F. Y. Generated Samples of Dataset 2 from Calochallenge_2022. Zenodo, 17 Feb. 2025, doi:10.5281/zenodo.14883798.&#160;<a href=#fnref:34 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:35><p>CaloChallenge Homepage*, calochallenge.github.io/homepage/. Accessed 3 Mar. 2025.&#160;<a href=#fnref:35 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:35 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:35 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:36><p>GitHub: <a href=https://github.com/Aaheer17/Benchmarking_Calorimeter_Shower_Simulation_Generative_AI/tree/main>https://github.com/Aaheer17/Benchmarking_Calorimeter_Shower_Simulation_Generative_AI/tree/main</a>&#160;<a href=#fnref:36 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:37><p>Michele Faucci Giannelli, Gregor Kasieczka, Claudius
Krause, Ben Nachman, Dalila Salamani, David Shih,
Anna Zaborowska, Fast calorimeter simulation challenge
2022 - dataset 1,2 and 3 [data set]. zenodo., <a href=https://doi.org/10.5281/zenodo.8099322>https://doi.org/10.5281/zenodo.8099322</a>, <a href=https://doi.org/10.5281/zenodo.6366271>https://doi.org/10.5281/zenodo.6366271</a>, <a href=https://doi.org/10.5281/zenodo.6366324>https://doi.org/10.5281/zenodo.6366324</a> (2022).&#160;<a href=#fnref:37 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:37 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:38><p>ATLAS Collaboration, ATLAS software and computing HL-LHC roadmap, Tech. Rep. (Technical report, CERN, Geneva. <a href=http://cds.cern.ch/record/2802918>http://cds.cern.ch/record/2802918</a>, 2022).&#160;<a href=#fnref:38 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:38 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:39><p><strong>Conditioned quantum-assisted deep generative surrogate for particle-calorimeter interactions, J Quetzalcoatl Toledo-Marin, Sebastian Gonzalez, Hao Jia, Ian Lu, Deniz Sogutlu, Abhishek Abhishek, Colin Gay, Eric Paquet, Roger Melko, Geoffrey C Fox, Maximilian Swiatlowski, Wojciech Fedorko, 2024/10/30
arXiv preprint arXiv:2410.22870, Abstract:
Particle collisions at accelerators such as the Large Hadron Collider, recorded and analyzed by experiments such as ATLAS and CMS, enable exquisite measurements of the Standard Model and searches for new phenomena. Simulations of collision events at these detectors have played a pivotal role in shaping the design of future experiments and analyzing ongoing ones. However, the quest for accuracy in Large Hadron Collider (LHC) collisions comes at an imposing computational cost, with projections estimating the need for millions of CPU-years annually during the High Luminosity LHC (HL-LHC) run \cite{collaboration2022atlas}. Simulating a single LHC event with \textsc{Geant4} currently devours around 1000 CPU seconds, with simulations of the calorimeter subdetectors in particular imposing substantial computational demands <sup id=fnref1:38><a href=#fn:38 class=footnote-ref role=doc-noteref>38</a></sup>. To address this challenge, we propose a conditioned quantum-assisted deep generative model. Our model integrates a conditioned variational autoencoder (VAE) on the exterior with a conditioned Restricted Boltzmann Machine (RBM) in the latent space, providing enhanced expressiveness compared to conventional VAEs. The RBM nodes and connections are meticulously engineered to enable the use of qubits and couplers on D-Wave&rsquo;s Pegasus-structured \textit{Advantage} quantum annealer (QA) for sampling. We introduce a novel method for conditioning the quantum-assisted RBM using \textit{flux biases}. We further propose a novel adaptive mapping to estimate the effective inverse temperature in quantum annealers. The effectiveness of our framework is illustrated using Dataset 2 of the CaloChallenge <sup id=fnref1:37><a href=#fn:37 class=footnote-ref role=doc-noteref>37</a></sup>.</strong>&#160;<a href=#fnref:39 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:40><p><strong>Calorimeter Surrogate Research, Geoffrey Fox University of Virginia, 2024
<a href=https://docs.google.com/document/d/19g0Avj9SYbVH7qSxoVUnnFKeGMuBdD9JCHVmBQB466M/>https://docs.google.com/document/d/19g0Avj9SYbVH7qSxoVUnnFKeGMuBdD9JCHVmBQB466M/</a></strong>&#160;<a href=#fnref:40 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:41><p><strong>Poster: <a href=https://drive.google.com/file/d/1PUiNDju_8N_wsDKI_W-g-jyCHb_5Hepo/>https://drive.google.com/file/d/1PUiNDju_8N_wsDKI_W-g-jyCHb_5Hepo/</a></strong>&#160;<a href=#fnref:41 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:42><p><strong>Extended abstract: Correlation Frobenius Distance: A Metric for Evaluating Generative Models in Calorimeter Shower Simulation, Farzana Yasmin Ahmada, Vanamala Venkataswamya, Geoffrey Fox, University of Virginia,
<a href=https://docs.google.com/document/d/1ndHkJY41_pHYZZne58B4_7HJQKTCxPzeMWVMJ0bsnOE>https://docs.google.com/document/d/1ndHkJY41_pHYZZne58B4_7HJQKTCxPzeMWVMJ0bsnOE</a></strong>&#160;<a href=#fnref:42 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-386ca1030e8123ddf937ecb1eac2905c>3 - Virtual tissue</h1><div class=lead>This surrugate simulates a virtual tissue</div><h2 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h2><p>Neural networks (NNs) have been demonstrated to be a viable
alternative to traditional direct numerical evaluation algorithms,
with the potential to accelerate computational time by several orders
of magnitude. In the present paper we study the use of encoder-decoder
convolutional neural network (CNN) algorithms as surrogates for
steady-state diffusion solvers. The construction of such surrogates
requires the selection of an appropriate task, network architecture,
training set structure and size, loss function, and training algorithm
hyperparameters. It is well known that each of these factors can have
a significant impact on the performance of the resultant model. Our
approach employs an encoder-decoder CNN architecture, which we posit
is particularly wellsuited for this task due to its ability to
effectively transform data, as opposed to merely compressing it. We
systematically evaluate a range of loss functions, hyperparameters,
and training set sizes. Our results indicate that increasing the size
of the training set has a substantial effect on reducing performance
fluctuations and overall error. Additionally, we observe that the
performance of the model exhibits a logarithmic dependence on the
training set size. Furthermore, we investigate the effect on model
performance by using different subsets of data with varying
features. Our results highlight the importance of sampling the
configurational space in an optimal manner, as this can have a
significant impact on the performance of the model and the required
training time. In conclusion, our results suggest that training a
model with a pre-determined error performance bound is not a viable
approach, as it does not guarantee that edge cases with errors larger
than the bound do not exist. Furthermore, as most surrogate tasks
involve a high dimensional landscape, an ever increasing training set
size is, in principle, needed, however it is not a practical solution.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:959px><img class=card-img-top src=/docs/surrogates/virtualtissue/virtualtissue_hu4ece9ae9fa528d24b54d235d7699b339_80460_949x300_fill_catmullrom_smart1_3.png width=949 height=300><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: Sketch of the NN architecture for virtual tissue surrogate.</p></figcaption></figure><p><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup>,</sup><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Analyzing the Performance of Deep Encoder-Decoder Networks as Surrogates for a Diffusion Equation, J. Quetzalcoatl Toledo-Marin, James A. Glazier, Geoffrey Fox
<a href=https://arxiv.org/pdf/2302.03786.pdf>https://arxiv.org/pdf/2302.03786.pdf</a>>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>There is an earlier surrogate referred to in this arxiv. It was published:
Toledo-Marín J. Quetzalcóatl , Fox Geoffrey , Sluka James P. , Glazier James A.,
Deep Learning Approaches to Surrogates for Solving the Diffusion Equation for Mechanistic Real-World Simulations,Frontiers in Physiology, Vol. 12, 2021
doi: 10.3389/fphys.2021.667828,
ISSNI 1664-042X,
<a href=https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2021.667828>https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2021.667828</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-c81d71fde3c0ee4014394d74adc53de0>4 - Cosmoflow</h1><div class=lead>The CosmoFlow training application benchmark from the MLPerf HPC v0.5 benchmark suite. It involves training a 3D convolutional neural network on N-body cosmology simulation data to predict physical parameters of the universe.</div><hr><h2 id=metadata>Metadata<a class=td-heading-self-link href=#metadata aria-label="Heading self-link"></a></h2><hr><p><strong>Model</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/models/c/cosmoflow.json>cosmoflow.json</a></p><p><strong>Datasets</strong></p><p><a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/datasets/c/cosmoUniverse_2019_05_4parE_tf_v2.json>cosmoUniverse_2019_05_4parE_tf_v2.json</a></p><p><a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/datasets/c/cosmoUniverse_2019_05_4parE_tf_v2_mini.json>cosmoUniverse_2019_05_4parE_tf_v2_mini.json</a></p><hr><h2 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h2><p>This application is based on the original CosmoFlow paper presented at SC18 and continued by the ExaLearn project, and adopted as a benchmark in the MLPerf HPC suite. It involves training a 3D convolutional neural network on N-body cosmology simulation data to predict physical parameters of the universe. The reference implementation for MLPerf HPC v0.5 CosmoFlow uses TensorFlow with the Keras API and Horovod for data-parallel distributed training. The dataset comes from simulations run by ExaLearn, with universe volumes split into cubes of size 128x128x128 with 4 redshift bins. The total dataset volume preprocessed for MLPerf HPC v0.5 in TFRecord format is 5.1 TB. The target objective in MLPerf HPC v0.5 is to train the model to a validation mean-average-error &lt; 0.124. However, the problem size can be scaled down and the training throughput can be used as the primary objective for a small scale or shorter timescale benchmark.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:938px><img class=card-img-top src=/docs/surrogates/cosmoflow/cosmoflow_hub95de84566b8bf0f0a840dc39a9b7150_118291_928x900_fill_q75_catmullrom_smart1.jpg width=928 height=900><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: Example simulation of dark matter in the universe used as input to the CosmoFlow network.
Copied from [NERSC](https://www.nersc.gov/news-publications/nersc-news/science-news/2018/nersc-intel-cray-harness-the-power-of-deep-learning-to-better-understand-the-universe/)</p></figcaption></figure><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://proxyapps.exascaleproject.org/app/mlperf-cosmoflow/>https://proxyapps.exascaleproject.org/app/mlperf-cosmoflow/</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://github.com/sparticlesteve/cosmoflow-benchmark>https://github.com/sparticlesteve/cosmoflow-benchmark</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://github.com/sparticlesteve/cosmoflow-benchmark/blob/master/README.md>https://github.com/sparticlesteve/cosmoflow-benchmark/blob/master/README.md</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f33b00fce1cb69e54b44c3dacba3bfad>5 - Fully ionized plasma fluid model closures</h1><div class=lead>The closure problem in fluid modeling is a well-known challenge to modelers aiming to accurately describe their system of interest. We will choose one of the surrogates form this application and develop a reference implementation and tutorial.</div><p>Fully ionized plasma fluid model closures (Argonne):<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> The closure
problem in fluid modeling is a well-known challenge to modelers aiming
to accurately describe their system of interest. Analytic formulations
in a wide range of regimes exist but a practical, generalized fluid
closure for magnetized plasmas remains an elusive goal. There are
scenarios where complex physics prevents a simple closure being
assumed, and the question as to what closure to employ has a
non-trivial answer. In a proof-of-concept study, Argonne researchers
turned to machine learning to try to construct surrogate closure
models that map the known macroscopic variables in a fluid model to
the higher-order moments that must be closed. In their study, the
researchers considered three closures: Braginskii, Hammett-Perkins,
and Guo-Tang; for each of them, they tried three types of ANNs:
locally connected, convolutional, and fully connected. Applying a
physics-informed machine learning approach, they found that there is a
benefit to tailoring a specific network architecture informed by the
physics of the plasma regime each closure is designed for, rather than
carelessly applying an unnecessarily complex general network
architecture. will choose one of the surrogates and bring it up an
early example for SBI with reference implementation and tutorial
documentation. As a follow-up, the Argonne team will tackle more
challenging problems.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1610px><img class=card-img-top src=/docs/surrogates/ionized-plasma/plasma_huf5a4cf579253a6a452cc06a8d2bdd748_201640_1600x910_fill_catmullrom_smart1_3.png width=1600 height=910><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: Simple schematic of varying classes of closure formulations.</p></figcaption></figure><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>R. Maulik, N. A. Garland, X.-Z. Tang, and P. Balaprakash,
“Neural network representability of fully ionized plasma fluid
model closures,” arXiv [physics.comp-ph], 10-Feb-2020
[Online]. Available: <a href=http://arxiv.org/abs/2002.04106>http://arxiv.org/abs/2002.04106</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-78e52a1336c6e0869c51f7cf3eef7d30>6 - Ions in nanoconfinement</h1><div class=lead>This application studies ionic structure in electrolyte solutions in nanochannels with planar uncharged surfaces and can use multiple molecular dynamics (MD) codes including LAMMPS which run on HPC supercomputers with OpenMP and MPI parallelization.</div><h2 id=metadata>Metadata<a class=td-heading-self-link href=#metadata aria-label="Heading self-link"></a></h2><hr><p><strong>Model</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/models/n/nanoconfinement.json>nanoconfinement.json</a></p><p><strong>Datasets</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/datasets/n/nanoconfinement.json>nanoconfinement.json</a></p><hr><p>This application <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> studies
ionic structure in electrolyte solutions in nanochannels with planar
uncharged surfaces and can use multiple molecular dynamics (MD) codes
including LAMMPS <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> which run on HPC supercomputers with OpenMP and
MPI parallelization.</p><p>A dense neural-net (NN) was used to learn 150 final state
characteristics based on the input of 5 parameters with typical
results shown in fig. 2(b) with the NN results for three important
densities tracking well the MD simulation results for a wide range of
unseen input system parameters. Fig. 3(a,b) shows two typical density
profiles with again the NN prediction tracking well the
simulation. Input quantities were confinement length, positive ion
valency, negative ion valency, salt concentration, and ion
diameter. Figure 2(a) shows the runtime architecture for dynamic use
and update of the NN and our middleware discussed in Sec. 3.2.6 will
generalize this. The inference time for this on a single core is 104
times faster than the parallel code which is itself 100 times the
sequential code. This surrogate approach is the first-of-its-kind in
the area of simulating charged soft-matter systems and there are many
other published papers in both biomolecular and material science
presenting similar successful surrogates <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> with a NN architecture
similar to fig. 3(c).</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:935px><img class=card-img-top src=/docs/surrogates/ions-in-nanoconfinement/featured-ion1_hu54f46d044c4e12dbdf720fb8ecb29dcc_251133_925x254_fill_catmullrom_smart1_3.png width=925 height=254><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Fig. 2 a) Architecture of dynamic training of ML surrogate and b)
Comparison of three final state densities (peak, contact, and center)
between MD simulations and NN surrogate predictions [^5] [^51].</p></figcaption></figure><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:948px><img class=card-img-top src=/docs/surrogates/ions-in-nanoconfinement/featured-ion2_hu04e0f7269f76594d4a25e14f4e4eee06_144655_938x222_fill_catmullrom_smart1_3.png width=938 height=222><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Fig. 3 (a,b) Two density profiles of confined ions for very different
input parameters and comparing MD and NN. (c) Fully connected deep
learning network used to learn the final densities. ReLU activation
units are in the 512 and 256 node hidden layers. The output values
were learned on 150 nodes.</p></figcaption></figure><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>JCS Kadupitiya , Geoffrey C. Fox , and Vikram Jadhao, “Machine
learning for performance enhancement of molecular dynamics
simulations,” in International Conference on Computational
Science ICCS2019, Faro, Algarve, Portugal, 2019
[Online]. Available:
<a href=http://dsc.soic.indiana.edu/publications/ICCS8.pdf>http://dsc.soic.indiana.edu/publications/ICCS8.pdf</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>J. C. S. Kadupitiya, F. Sun, G. Fox, and V. Jadhao, “Machine
learning surrogates for molecular dynamics simulations of soft
materials,” J. Comput. Sci., vol. 42, p. 101107, Apr. 2020
[Online]. Available:
<a href=http://www.sciencedirect.com/science/article/pii/S1877750319310609>http://www.sciencedirect.com/science/article/pii/S1877750319310609</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>“Molecular Dynamics for Nanoconfinement.” [Online]. Available:
<a href=https://github.com/softmaterialslab/nanoconfinement-md>https://github.com/softmaterialslab/nanoconfinement-md</a>. [Accessed: 11-May-2020]&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>S. Plimpton, “Fast Parallel Algorithms for Short Range
Molecular Dynamics,” J. Comput. Phys., vol. 117, pp. 1–19, 1995
[Online]. Available:
<a href=http://faculty.chas.uni.edu/~rothm/Modeling/Parallel/Plimpton.pdf>http://faculty.chas.uni.edu/~rothm/Modeling/Parallel/Plimpton.pdf</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Geoffrey Fox, Shantenu Jha, “Learning Everywhere: A Taxonomy for
the Integration of Machine Learning and Simulations,” in IEEE
eScience 2019 Conference, San Diego, California
[Online]. Available: <a href=https://arxiv.org/abs/1909.13340>https://arxiv.org/abs/1909.13340</a>&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-4ffb8f290e64e79568dc14ea45423d53>7 - Molecule docking</h1><div class=lead>Docking small molecules to a protein’s binding site is often one of the first steps for virtual screening. This application is realated to CANDLE and provides a valubale example.</div><p>Molecule docking: Docking small molecules to a protein’s
binding site is often one of the first steps for virtual screening
<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. Although many open-source and commercial packages exist for
docking, AI approaches can be equally powerful (and computationally
more efficient) for docking studies <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Utilizing advances in
control from reinforcement learning (RL), Argonne researchers trained
an agent to drive the docking of a rigid ligand into a flexible
protein pocket. The RL agent treats the ligand as a rigid body to
which it can move through affine transformations along the
protein. This procedure bypasses sampling on a grid as the agent is
trained to optimize the pose against OpenEye Fred docking function
<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, and/or other openly available docking tools such as UCSF DOCK,
Autodock/Vina. The challenge of this approach is that there is a need
to train the agent based on the protein target, which can still take
considerable time on single-GPU systems. This area comes from the
major Argonne CANDLE <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> project and other applications (DeepDriveMD)
will come from this project in the new submissions category.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:1083px><img class=card-img-top src=/docs/surrogates/molecule-docking/candle_hu3c655206915f54c1b846814e3f72fce5_356062_1073x735_fill_catmullrom_smart1_3.png width=1073 height=735><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: CANcer Distributed Learning Environment</p></figcaption></figure><h2 id=refernces>Refernces<a class=td-heading-self-link href=#refernces aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>P. D. Lyne, “Structure-based virtual screening: an overview,”
Drug Discov. Today, vol. 7, no. 20, pp. 1047–1055, Oct. 2002
[Online]. Available:
<a href=http://dx.doi.org/10.1016/s1359-6446(02)02483-2>http://dx.doi.org/10.1016/s1359-6446(02)02483-2</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>J. Li, A. Fu, and L. Zhang, “An overview of scoring functions
used for protein&ndash;ligand interactions in molecular docking,”
Interdiscip. Sci., pp. 1–9, 2019 [Online]. Available:
<a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s12539-019-00327-w&amp;casa_token=Usuqtf4tu-4AAAAA:VD0uKAo49lSwaEEpmufft87cpUtbmE9MSdlR_Wpv880jHArsLIfLy8PQPAaN6ODJIArQ9GMz15wJ6lSX">https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s12539-019-00327-w&amp;casa_token=Usuqtf4tu-4AAAAA:VD0uKAo49lSwaEEpmufft87cpUtbmE9MSdlR_Wpv880jHArsLIfLy8PQPAaN6ODJIArQ9GMz15wJ6lSX</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>M. McGann, “FRED pose prediction and virtual screening
accuracy,” J. Chem. Inf. Model., vol. 51, no. 3, pp. 578–596,
Mar. 2011 [Online]. Available:
<a href=http://dx.doi.org/10.1021/ci100436p>http://dx.doi.org/10.1021/ci100436p</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>“CANDLE Exascale Deep Learning and Simulation Enabled Precision
Medicine for Cancer.” [Online]. Available:
<a href=https://candle.cels.anl.gov/>https://candle.cels.anl.gov/</a>. [Accessed: 01-May-2020]&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-da679368f9d15b0486abed0d11a2ce9a>8 - miniWeatherML</h1><div class=lead>A simplified weather model simulating flows such as supercells that are realistic enough to be challenging and simple enough for rapid prototyping in creating and learning about surrogates.</div><hr><h2 id=metadata>Metadata<a class=td-heading-self-link href=#metadata aria-label="Heading self-link"></a></h2><hr><p><strong>Model</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/models/m/miniWeatherML.json>miniWeatherML.json</a></p><p><strong>Datasets</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/datasets/m/miniWeatherML.json>miniWeatherML.json</a></p><hr><h2 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h2><p>MiniWeatherML is a playground for learning and developing Machine Learning (ML) surrogate models and workflows. It is based on a simplified weather model simulating flows such as supercells that are realistic enough to be challenging and simple enough for rapid prototyping in:</p><ul><li>Data generation and curation</li><li>Machine Learning model training</li><li>ML model deployment and analysis</li><li>End-to-end workflows</li></ul><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:510px><img class=card-img-top src=/docs/surrogates/miniweatherml/weather_hu5e8599bfb2e591cc67963ae5090a8232_2812795_500x500_fill_catmullrom_smart1_1.gif width=500 height=500><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: CANcer Distributed Learning Environment</p></figcaption></figure><img src=https://camo.githubusercontent.com/f7d00138e4e45ee24367fc16bc6f7de194c1c5a1ceebb03f85fb0c1cdcc4e314/68747470733a2f2f6d726e6f726d616e2e6769746875622e696f2f737570657263656c6c5f6d696e69576561746865724d4c2e676966><p><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>,<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://github.com/mrnorman/miniWeatherML>https://github.com/mrnorman/miniWeatherML</a><sup>,</sup>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://github.com/mrnorman/miniWeatherML/wiki>https://github.com/mrnorman/miniWeatherML/wiki</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-6e66623ebf80ce302fd399a8dd6f8d7b>9 - OSMI</h1><div class=lead>We explore the relationship between certain network configurations and the performance of distributed Machine Learning systems. We build upon the Open Surrogate Model Inference (OSMI) Benchmark, a distributed inference benchmark for analyzing the performance of machine-learned surrogate models</div><h2 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h2><p>We explore the relationship between certain network configurations and
the performance of distributed Machine Learning systems. We build upon
the Open Surrogate Model Inference (OSMI) Benchmark, a distributed
inference benchmark for analyzing the performance of machine-learned
surrogate models developed by Wes Brewer et. Al. We focus on analyzing
distributed machine-learning systems, via machine-learned surrogate
models, across varied hardware environments. By deploying the OSMI
Benchmark on platforms like Rivanna HPC, WSL, and Ubuntu, we offer a
comprehensive study of system performance under different
configurations. The paper presents insights into optimizing
distributed machine learning systems, enhancing their scalability and
efficiency. We also develope a framework for automating the OSMI
benchmark.</p><h2 id=introdcution>Introdcution<a class=td-heading-self-link href=#introdcution aria-label="Heading self-link"></a></h2><p>With the proliferation of machine learning as a tool for science, the
need for efficient and scalable systems is paramount. This paper
explores the Open Surrogate Model Inference (OSMI) Benchmark, a tool
for testing the performance of machine-learning systems via
machine-learned surrogate models. The OSMI Benchmark, originally
created by Wes Brewer and colleagues, serves to evaluate various
configurations and their impact on system performance.</p><p>Our research pivots around the deployment and analysis of the OSMI
Benchmark across various hardware platforms, including the
high-performance computing (HPC) system Rivanna, Windows Subsystem for
Linux (WSL), and Ubuntu environments.</p><p>In each experiment, there are a variable number of TensorFlow model
server instances, overseen by a HAProxy load balancer that distributes
inference requests among the servers. Each server instance operates on
a dedicated GPU, choosing between the V100 or A100 GPUs available on
Rivanna. This setup mirrors real-world scenarios where load balancing
is crucial for system efficiency.</p><p>On the client side, we initiate a variable number of concurrent
clients executing the OSMI benchmark to simulate different levels of
system load and analyze the corresponding inference throughput.</p><p>On top of the original OSMI-Bench, we implemented an object-oriented
interface in Python for running experiments with ease, streamlining
the process of benchmarking and analysis. The experiments rely on
custom-built images based on NVIDIA&rsquo;s tensorflow image. The code works
on several hardwares, assuming the proper images are built.</p><p>Additionally, We develop a script for launching simultaneous
experiments with permutations of pre-defined parameters with Cloudmesh
Experiment-Executor. The Experiment Executor is a tool that automates
the generation and execution of experiment variations with different
parameters. This automation is crucial for conducting tests across a
spectrum of scenarios.</p><p>Finally, we analyze the inference throughput and total time for each
experiment. By graphing and examining these results, we draw critical
insights into the performance dynamics of distributed machine learning
systems.</p><p>In summary, a comprehensive examination of the OSMI Benchmark in
diverse distributed ML systems is provided. We aim to contribute to
the optimization of these systems, by providing a framework for
finding the best performant system configuration for a given use
case. Our findings pave the way for more efficient and scalable
distributed computing environments.</p><p>The architectural view of the benchmarks are depictued in Figure 1 and
Figure 2.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:938px><img class=card-img-top src=/docs/surrogates/osmi/osmi1_hu7c0ce91db4341889bc7ce96dfb596a67_74813_928x306_fill_catmullrom_smart1_3.png width=928 height=306><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 1: Surrogate calculations via a Inference Server.</p></figcaption></figure><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:2911px><img class=card-img-top src=/docs/surrogates/osmi/osmi2_hufa595329706607e7c24e0c5ae57ccfec_402285_2901x1173_fill_catmullrom_smart1_3.png width=2901 height=1173><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Figure 2: Possible benchmark configurations to measure sped of parallel iference.</p></figcaption></figure><p><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup><sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup><sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup><sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup></p><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Brewer, Wesley, Daniel Martinez, Mathew Boyer, Dylan Jude, Andy
Wissink, Ben Parsons, Junqi Yin, and Valentine Anantharaj. &ldquo;Production
Deployment of Machine-Learned Rotorcraft Surrogate Models on HPC.&rdquo; In
2021 IEEE/ACM Workshop on Machine Learning in High Performance
Computing Environments (MLHPC), pp. 21-32. IEEE, 2021,
<a href=https://ieeexplore.ieee.org/abstract/document/9652868>https://ieeexplore.ieee.org/abstract/document/9652868</a>, Note that
OSMI-Bench differs from SMI-Bench described in the paper only in that
the models that are used in OSMI are trained on synthetic data,
whereas the models in SMI were trained using data from proprietary CFD
simulations. Also, the OSMI medium and large models are very similar
architectures as the SMI medium and large models, but not identical.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Brewer, Wesley, Greg Behm, Alan Scheinine, Ben Parsons, Wesley Emeneker, and Robert P. Trevino. &ldquo;iBench: a distributed inference simulation and benchmark suite.&rdquo; In 2020 IEEE High Performance Extreme Computing Conference (HPEC), pp. 1-6. IEEE, 2020.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Brewer, Wesley, Greg Behm, Alan Scheinine, Ben Parsons, Wesley Emeneker, and Robert P. Trevino. &ldquo;Inference benchmarking on HPC systems.&rdquo; In 2020 IEEE High Performance Extreme Computing Conference (HPEC), pp. 1-9. IEEE, 2020.&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Brewer, Wesley, Chris Geyer, Dardo Kleiner, and Connor Horne. &ldquo;Streaming Detection and Classification Performance of a POWER9 Edge Supercomputer.&rdquo; In 2021 IEEE High Performance Extreme Computing Conference (HPEC), pp. 1-7. IEEE, 2021.&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p>Gregor von Laszewski, J. P. Fleischer, and Geoffrey
C. Fox. 2022. Hybrid Reusable Computational Analytics Workflow
Management with Cloudmesh. <a href=https://doi.org/10.48550/ARXIV.2210.16941>https://doi.org/10.48550/ARXIV.2210.16941</a>&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-e825d671002d82761de7d86a532a7008>10 - Particle dynamics</h1><div class=lead>Recurrent Neural Nets as a Particle Dynamics Integrator</div><p>Recurrent Neural Nets as a Particle Dynamics Integrator</p><p>The second IU initial application shows a rather different type of
surrogate and illustrates an SBI goal to collect benchmarks covering a
range of surrogate designs. Molecular dynamics simulations rely on
numerical integrators such as Verlet to solve Newton&rsquo;s equations of
motion. Using a sufficiently small time step to avoid discretization
errors, Verlet integrators generate a trajectory of particle positions
as solutions to the equations of motions. In <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup> <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>, the IU team
introduces an integrator based on recurrent neural networks that is
trained on trajectories generated using the Verlet integrator and
learns to propagate the dynamics of particles with timestep up to 4000
times larger compared to the Verlet timestep. As shown in Fig. 4
(right) the error does not increase as one evolves the system for the
surrogate while standard Verlet integration in Fig. 4 (left) has
unacceptable errors even for time steps of just 10 times that used in
an accurate simulation. The surrogate demonstrates a significant net
speedup over Verlet of up to 32000 for few-particle (1 - 16) 3D
systems and over a variety of force fields including the Lennard-Jones
(LJ) potential. This application uses a recurrent plus dense neural
network architecture and illustrates an important approach to learning
evolution operators which can be applied across a variety of fields
including Earthquake science (IU work in progress) and Fusion <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>.</p><figure class="card rounded p-2 td-post-card mb-4 mt-4" style=max-width:610px><img class=card-img-top src=/docs/surrogates/particle-dynamics/fetured-particle_hua979a54266f85630f033cca2147d9725_81454_600x300_fill_catmullrom_smart1_3.png width=600 height=300><figcaption class="card-body px-0 pt-2 pb-0"><p class=card-text>Fig. 4: Average error in position updates for 16 particles interacting
with an LJ potential, The left figure is standard MD with error
increasing for ∆t as 10, 40, or 100 times robust choice (0.001). On
the right is the LSTM network with modest error up to t = 106 even for
∆t = 4000 times the robust MD choice.</p></figcaption></figure><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>JCS Kadupitiya, Geoffrey C. Fox, Vikram Jadhao, “GitHub
repository for Simulating Molecular Dynamics with Large
Timesteps using Recurrent Neural Networks.”
[Online]. Available:
<a href=https://github.com/softmaterialslab/RNN-MD>https://github.com/softmaterialslab/RNN-MD</a>. [Accessed: 01-May-2020]&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>J. C. S. Kadupitiya, G. C. Fox, and V. Jadhao, “Simulating
Molecular Dynamics with Large Timesteps using Recurrent Neural
Networks,” arXiv [physics.comp-ph], 12-Apr-2020
[Online]. Available: <a href=http://arxiv.org/abs/2004.06493>http://arxiv.org/abs/2004.06493</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>J. C. S. Kadupitiya, G. Fox, and V. Jadhao, “Recurrent Neural
Networks Based Integrators for Molecular Dynamics Simulations,”
in APS March Meeting 2020, 2020 [Online]. Available:
<a href=http://meetings.aps.org/Meeting/MAR20/Session/L45.2>http://meetings.aps.org/Meeting/MAR20/Session/L45.2</a>. [Accessed: 23-Feb-2020]&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>J. Kates-Harbeck, A. Svyatkovskiy, and W. Tang, “Predicting
disruptive instabilities in controlled fusion plasmas through
deep learning,” Nature, vol. 568, no. 7753, pp. 526–531,
Apr. 2019 [Online]. Available:
<a href=https://doi.org/10.1038/s41586-019-1116-4>https://doi.org/10.1038/s41586-019-1116-4</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d65c9f63f13fcf64fe06b834161e6a0d>11 - PtychoNN: deep learning network for ptychographic imaging that predicts sample amplitude and phase from diffraction data.</h1><div class=lead>A DL-based approach to solve the ptychography data inversion problem that learns a direct mapping from the reciprocal space data to the sample amplitude and phase.</div><hr><h2 id=metadata>Metadata<a class=td-heading-self-link href=#metadata aria-label="Heading self-link"></a></h2><hr><p><strong>Model</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/models/p/ptychonn.json>ptychonn.json</a></p><p><strong>Datasets</strong> <a href=https://github.com/icl-utk-edu/sabath/blob/main/var/sabath/assets/sabath/datasets/p/ptychonn_20191008_39.json>ptychonn_20191008_39.json</a></p><hr><p>PtychoNN, uses a deep convolutional neural network to predict realspace structure and phase from far-field diffraction data. It recovers high fidelity amplitude and phase contrast images of a real sample hundreds of times faster
than current ptychography reconstruction packages and reduces sampling requirements <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Mathew J. Cherukara, Tao Zhou, Youssef Nashed, Pablo Enfedaque, Alex Hexemer, Ross J. Harder, Martin V. Holt; AI-enabled high-resolution scanning coherent diffraction imaging. Appl. Phys. Lett. 27 July 2020; 117 (4): 044103. <a href=https://doi.org/10.1063/5.0013065>https://doi.org/10.1063/5.0013065</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="td-footer__left col-6 col-sm-4 order-sm-1"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="User mailing list" aria-label="User mailing list"><a target=_blank rel=noopener href=https://groups.google.com/g/sbi-fair/c/YuwS0vegIJU/m/aWmNlEU7AAAJ aria-label="User mailing list"><i class="fa fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Gregor von Laszewski" aria-label="Gregor von Laszewski"><a target=_blank rel=noopener href=https://laszewski.github.io aria-label="Gregor von Laszewski"><i class="fab fa-twitter"></i></a></li></ul></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="Web Site GitHub" aria-label="Web Site GitHub"><a target=_blank rel=noopener href=https://github.com/sbi-fair/sbi-fair.github.io aria-label="Web Site GitHub"><i class="fab fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Organization GitHub" aria-label="Organization GitHub"><a target=_blank rel=noopener href=https://github.com/sbi-fair aria-label="Organization GitHub"><i class="fab fa-github"></i></a></li></ul></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"><span class=td-footer__copyright>&copy;
2018&ndash;2025
<span class=td-footer__authors>SBI FAIR Authors |</span></span><span class=td-footer__all_rights_reserved>All Rights Reserved</span><span class=ms-2><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></span></div></div></div></footer></div><script src=/js/main.min.21eb2c7b0fd82c0b22fa631416dc800bb198ba4ee5abe2276f555c9cc7863751.js integrity="sha256-Iessew/YLAsi+mMUFtyAC7GYuk7lq+Inb1VcnMeGN1E=" crossorigin=anonymous></script>
<script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script></body></html>