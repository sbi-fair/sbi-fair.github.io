
---
title: "Meeting Notes 09-26-2022"
linkTitle: "09-26-2022"
date: 2022-09-26
description: >
  Meeting Notes from 09-26-2022
---



**Minutes of SBI-FAIR September 26, 2022, Meeting**


**Present:** Kamil Iskra, Xiaodong Yu, Deborah Penchoff, Shantenu Jha, Geoffrey Fox, Piotr Luszczek, Baixi Sun. Vikram Jadhao, Gregor von Laszewski

**Updates**

**Virginia**

Geoffrey discussed



* The transfer of the DOE grant is still making progress
* He noted two nearly completed new surrogates
    *  paper on Tsunami simulation surrogates entitled “Forecasting tsunami inundation with convolutional neural networks for a potential Cascadia Subduction Zone rupture”
    * Rough draft of the diffusion model for cell simulations  GENERALIZATION AND TRANSFER LEARNING IN A DEEP DIFFUSION SURROGATE FOR MECHANISTIC REAL-WORLD SIMULATIONS. Interesting is the study of dataset sizes 5000-400,000 and the importance of dealing with the large numeric range in computed values
* He summarized the MLCommons status with the move to continuous (rolling) submissions rather than fixed date submissions

**Indiana University**



* Vikram presented some of his recent work 
* He studied sensitivity to input training set showing some dramatic effects from seemingly small changes -- removing one value of electrolyte concentration c

**Tennessee**

Piotr reported



* There was a Data Challenge at Smoky Mountain meeting with a smaller version of the Cloudmask dataset from MLCommons [2022 Challenge 6: SMCEFR: Sentinel-3 Satellite Dataset « SMC Data Challange 2021](https://smc-datachallenge.ornl.gov/ch6-satellite-datasets/) 
* Two Submitted papers: one on Performance Surrogate and the other a SABATH paper at HPEC Conference [IEEE HPEC](https://ieee-hpec.org/) 26th Annual 2022 IEEE High Performance Extreme Computing Virtual Conference 19 - 23 September 2022
    *  paper and  presentation  Deep Gaussian process with multitask and transfer learning for performance optimization
* Questions included reproducibility and overheads from using FAIR metadata
* It was asked if SABATH recorded training time; it does record loss versus epoch number.
* Tennessee will give a detailed presentation on SABATH next time.

**Rutgers**

Shantenu reported



* Drug and Quantum surrogates
* He noted a new DOE $25M award for climate surrogates revisiting the startling Oxford paper [https://iopscience.iop.org/article/10.1088/2632-2153/ac3ffa/meta](https://iopscience.iop.org/article/10.1088/2632-2153/ac3ffa/meta) and [https://arxiv.org/pdf/2001.08055v1](https://arxiv.org/pdf/2001.08055v1) 
* Work with Indiana University was continuing with efforts to get system running on Summit
* There was a discussion of Large Language models LLM and DOE interest in using them on scientific literature. There is a challenge with the current $10-100 million computing training cost possibly reaching a billion dollars.

**Argonne**



* Xiaodong Yu discussed the ASPLOS paper which was unfortunately rejected
* Baixi presented their results  commenting on referee remarks
* One question prompted observation that surrogate MODEL sizes are comparatively small
* Another question was answered by noting that scheduling was a one-time cost
* In some cases their custom training order outperformed the baseline training