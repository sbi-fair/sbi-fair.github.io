
---
title: "Meeting Notes 04-19-2021"
linkTitle: "04-19-2021"
date: 2021-04-19
description: >
  Meeting Notes from 04-19-2021
---



**Minutes of Meeting April 19, 2021**

**Links for Today’s Meeting**



* Indiana Update plus Overall Project Remarks [SBI-Meeting-IU-April19-2021](https://docs.google.com/presentation/d/1-Td2Fz9yk3GNwa0Z2jbsQk8I_02bMMUexLTRCO09bt4/edit?usp=sharing) 
* Tennessee Update Presentation [sbi20210419.pdf](https://drive.google.com/file/d/1mv_EpqETFrMmt4fxYSYLrgDOzOL1xlqU/view?usp=sharing) 

**Updates**



* **Argonne** postponed their update to the next meeting and the other 3 sites gave updates.
* **Indiana** discussed SciMLBench from the UK with its first [release](https://github.com/stfc-sciml/sciml-bench ) and the related MLCommons Science benchmarking. With surrogates, Jadhao will work on the nanoengineering one in the Fall and Fox completed an initial study of a virtual tissue surrogate  [[2102.05527] Deep learning approaches to surrogates for solving the diffusion equation for mechanistic real-world simulations](https://arxiv.org/abs/2102.05527).
* **Tennessee** gave a comprehensive report covering their Surrogate Performance Model for Autotuning; their [FK6D / ASGarD · GitLab](https://code.ornl.gov/FK6D/FK6D) project aimed at a later release of SCiMLBench and an insightful analysis of issues and needed ontologies for a FAIR approach to benchmark data. The discussion pointed out that FAIR does not address areas like validation, verification, and reproducibility. Piotr introduced broad categories: Hardware, firmware, dataset, software, measurements. We know from MLPerf that I/O specification and measurement are nontrivial. The mode of execution: capability or capacity(high-throughput) needs to be specified. Gregor noted complications from the use of containers that can hide software versioning. Christine Kirkpatrick's [Advancing AI through MLCommons](https://drive.google.com/file/d/1VECDSbrh8N6mvn7g4bsBkSGesiOyAtAW/view?usp=sharing) to MLCommons Benchmark-Infra WG April 6 highlighted tension between the flexibility of free text and FAIR machine readability
* **Rutgers **Shantenu Jha discussed recent work by his group on computational performance. He pointed out a recent paper by Alexandru Iosup on [GradeML: Towards Holistic Performance Analysis for Machine Learning Workflows](https://dl.acm.org/doi/pdf/10.1145/3447545.3451185)

**Discussion and Action Items**



* We agreed to start two working groups on FAIR (coordinated by Piotr) and Surrogates (coordinated by Shantenu). The scope of both groups was unclear as yet and should be discussed in meetings
* There was a discussion of access to computers across the collaboration
* We discussed Surrogate Software and Benchmark software with work of Deep500 (Torsten Hoefler of ETH Zurich), GradeML, MLCube, SciMLBench mentioned. We need to relate it to FAIR
* We still need to implement SBI repository 
* We agreed in the March meeting to enhance the website with updated (after proposal) information. Please send your GitHub ID’s to Gregor laszewski@gmail.com  so he can enable to directly edit web site
    * Only Gregor contributed so far with core site [https://sbi-fair.github.io/](https://sbi-fair.github.io/)  
    * Not all GitHub invitations have been accepted
* Deborah Penchoff of UTK identified a t[emplate](https://docs.google.com/document/d/15wu_5Z76lmOAyNchwZynhudparJ8qKnsvCmkTq9jYec/edit?usp=sharing) for DOE annual report. We should accumulate the needed contributions
* We agreed to set the next meeting for 1-2 pm Eastern May 24 2021 at the usual zoom [https://iu.zoom.us/j/2301429329](https://iu.zoom.us/j/2301429329) 